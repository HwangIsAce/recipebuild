{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLM Tester\n",
    "* Model 선언\n",
    "* Load from folder\n",
    "* Data load\n",
    "* Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "from typing import Optional\n",
    "\n",
    "## custom load\n",
    "import bootstrap\n",
    "import datasets\n",
    "import evaluate\n",
    "# custom config load\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from ingt_tokenizer import IngtTokenizer\n",
    "from transformers import (CONFIG_MAPPING, MODEL_FOR_MASKED_LM_MAPPING,\n",
    "                          AutoConfig, AutoModelForMaskedLM, AutoTokenizer,\n",
    "                          DataCollatorForLanguageModeling, HfArgumentParser,\n",
    "                          Trainer, TrainingArguments, is_torch_tpu_available,\n",
    "                          set_seed)\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "# from transformers.utils import check_min_version, send_example_telemetry\n",
    "from transformers.utils import send_example_telemetry\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "## custom load\n",
    "\n",
    "VOCAB_CONFIG = \"ingr_title\"  # 'ingr_only' or 'ingr_title' (ing_title -> memory error)\n",
    "# VOCAB_CONFIG    =   'ingr_title' # 'ingr_only' or 'ingr_title'\n",
    "CONFIG_PATH = \"/home/donghee/projects/mlm/config.json\"\n",
    "\n",
    "ingt_config = bootstrap.IngTConfig(vocab=VOCAB_CONFIG, path=CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_FOR_MASKED_LM_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class args:\n",
    "#     data_folder = '/media/ssd/dh/projects/ing_mlm/test_output'\n",
    "#     model_name_or_path = '/media/ssd/dh/projects/ing_mlm/test_output/checkpoint-5500'\n",
    "# class args:\n",
    "#     data_folder = '/media/ssd/dh/projects/ing_mlm/test_output_2023-03-06-20-47'\n",
    "#     model_name_or_path = '/media/ssd/dh/projects/ing_mlm/checkpoints/v1-ing-only_2023-03-06-20-51/checkpoint-56000'\n",
    "\n",
    "class args:\n",
    "    data_folder = '/disk1/data/ing_mlm_data/processed/v2_ing_title_sample/test.txt'\n",
    "    model_name_or_path = '/home/donghee/projects/mlm/checkpoints/v2-ing-title_2023-08-03-12-02/checkpoint-60000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/disk1/data/ing_mlm_data/processed/v2_ing_title_sample/test.txt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingt_tokenizer = IngtTokenizer(ingt_config)\n",
    "ingt_tokenizer.load()\n",
    "tokenizer = ingt_tokenizer.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"/home/donghee/projects/mlm/checkpoints/v2-ing-title_2023-08-03-12-02/checkpoint-60000\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 3,\n",
       "  \"num_hidden_layers\": 3,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.30.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 171490\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(args.model_name_or_path)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\n",
    "            args.model_name_or_path,\n",
    "            config=config,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bisquick',\n",
       " 'whole_kernel_corn',\n",
       " 'cheddar_cheese',\n",
       " 'milk',\n",
       " 'water',\n",
       " 'butter',\n",
       " 'potatoes',\n",
       " 'crunchy',\n",
       " 'onion',\n",
       " 'potato',\n",
       " 'sour_cream']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs = tokenizer(\"lentils salt_and_black_pepper vegetable_broth white_pepper chili_powder extra_virgin_olive_oil garlic_powder celery carrots tomatoes onions water\", return_tensors=\"pt\")\n",
    "\n",
    "# test -> \n",
    "# completion 맨마지막을 전부 [MASK] -> answer : water\n",
    "# ideation ing1 ing2 [MASK] ing3 [MASK] ing4 ing5 -> -100 -100 ing100 -100 ing200\n",
    "\n",
    "inputs = tokenizer(\"[MASK] whole_kernel_corn cheddar_cheese milk water butter[SEP]Crunchy Onion Potato Bake\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs )\n",
    "# outputs = model(**inputs,output_attentions=True )\n",
    "# outputs = model(**inputs, output_hidden_states=True)\n",
    "# outputs\n",
    "tokenizer.convert_ids_to_tokens(torch.argmax(outputs.logits, dim=2).reshape(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 171490])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.6294, -6.9249, -5.4099,  ..., -5.8047, -6.7900, -5.0061],\n",
       "        [-6.4214, -5.4866, -6.5880,  ..., -5.7604, -5.1726, -6.4609],\n",
       "        [-6.0903, -7.2667, -4.9855,  ..., -6.7639, -6.0559, -5.2878],\n",
       "        ...,\n",
       "        [-5.5508, -5.0793, -5.7811,  ..., -4.6969, -6.7108, -6.2666],\n",
       "        [-5.4562, -4.7530, -5.3175,  ..., -5.0579, -7.3074, -5.0504],\n",
       "        [-7.6900, -8.9001, -7.0929,  ..., -7.8584, -8.0195, -7.1072]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3152, 2345,  732,  295,  256,  202,  498, 3408,  218,  712,  458])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(outputs.logits, dim=2).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3152)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(outputs.logits[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['water',\n",
       " 'eggs',\n",
       " 'flour',\n",
       " 'onion',\n",
       " 'onions',\n",
       " 'butter',\n",
       " 'sugar',\n",
       " 'garlic_cloves',\n",
       " 'olive_oil',\n",
       " 'boiling_water',\n",
       " 'warm_water',\n",
       " 'hot_water',\n",
       " 'milk',\n",
       " 'pepper',\n",
       " 'chicken_broth',\n",
       " 'celery',\n",
       " 'egg',\n",
       " 'green_onions',\n",
       " 'garlic',\n",
       " 'garlic_powder']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(torch.topk(outputs.logits[0][4], 20).indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['water', 'olive_oil', 'water', 'water', 'water', 'water', 'water', 'water']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
